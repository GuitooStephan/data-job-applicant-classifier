{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa92176f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:09.360867Z",
     "start_time": "2022-06-07T21:19:08.117691Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from re import search\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce5b8055",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:10.074909Z",
     "start_time": "2022-06-07T21:19:10.068339Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    current_working_dir = os.path.abspath(os.getcwd())\n",
    "    file_path = os.path.join(current_working_dir, 'models', filename)\n",
    "    joblib.dump(obj, file_path)\n",
    "    \n",
    "def load_object(filename):\n",
    "    current_working_dir = os.path.abspath(os.getcwd())\n",
    "    file_path = os.path.join(current_working_dir, 'models', filename)\n",
    "    obj = joblib.load(file_path)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b702a953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:10.855590Z",
     "start_time": "2022-06-07T21:19:10.848727Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_technologies = [\n",
    "    'ruby', 'windows', 'oracle', 'mysql', 'hadoop(hdfs)', 'nosq', 'redshift', 'pig', 'map-reduce', 'hbase',\n",
    "    'yarn', 'postgresql', 'kafka', 'tableau', 'vertica', 'mariadb', 'hdfs', 'numpy', 'deep learning', 'ai', 'scoring',\n",
    "    'matplotlib', 'pycharm', 'scikit-learn', 'tensorflow', 'teradata', 'anglais', 'big data', 'r', 'machine learning', \n",
    "    'microsoft azure', 'spss', 'excel', 'sas', 'vba', 'matlab', 'aws', 'gnu', 'linux'\n",
    "]\n",
    "selected_features = [ *selected_technologies, 'Experience' ]\n",
    "target_feature = 'Metier'\n",
    "\n",
    "pipeline_filename = 'pipeline.joblib'\n",
    "target_encoder_filename = 'label_encoder.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e941615d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:11.213418Z",
     "start_time": "2022-06-07T21:19:11.201768Z"
    }
   },
   "outputs": [],
   "source": [
    "class CreateIndividualTechnologyColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, technologies):\n",
    "        self.technologies = np.array(selected_technologies)\n",
    "    \n",
    "    def set_individual_technology(self, row):\n",
    "        row_technologies = np.array(list(filter(None, row['Technologies'].lower().strip().split('/'))))\n",
    "        individual_technologies = np.isin(self.technologies, row_technologies).astype(int)\n",
    "        return np.concatenate((row, individual_technologies))\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_ = X.copy()\n",
    "        transformed_X = X_.apply(\n",
    "            self.set_individual_technology,\n",
    "            axis=1,\n",
    "            result_type='expand'\n",
    "        )\n",
    "        transformed_X.columns = [*X_.columns, *self.technologies.tolist()]\n",
    "        return transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35ff11c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:11.970746Z",
     "start_time": "2022-06-07T21:19:11.965872Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformExperienceColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_ = X.copy()\n",
    "        X_['Experience'] = X_['Experience'].str.replace(',', '.').astype(float)\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318e3420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:12.383357Z",
     "start_time": "2022-06-07T21:19:12.376824Z"
    }
   },
   "outputs": [],
   "source": [
    "class DropNotSelectedColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, selected_features):\n",
    "        self.selected_features = selected_features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_ = X.copy()\n",
    "        result = X_[self.selected_features]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f6ef040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:12.958627Z",
     "start_time": "2022-06-07T21:19:12.950341Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_raw_data(df):\n",
    "    _df = df.drop_duplicates()\n",
    "    _df = df.dropna(subset=['Experience'])\n",
    "    return _df\n",
    "\n",
    "def split_train_data_raw(data, target_feature):\n",
    "    le = LabelEncoder()\n",
    "    X = data.drop(target_feature, axis=1)\n",
    "    y = le.fit_transform(data[target_feature])\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "    \n",
    "    save_object(le, target_encoder_filename)\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "def predict(data):\n",
    "    pipeline = load_object(pipeline_filename)\n",
    "    y_pred = pipeline.predict(data)\n",
    "    return y_pred\n",
    "\n",
    "def train_model(X, y):\n",
    "    # Train\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('experience_transformer', TransformExperienceColumn()),\n",
    "            ('individual_technologies', CreateIndividualTechnologyColumns(selected_technologies)),\n",
    "            ('drop_not_selected_columns', DropNotSelectedColumns(selected_features)),\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "            ('classifier', RandomForestClassifier(\n",
    "                n_estimators=52, class_weight={0: 1, 1: 1, 2: 1, 3: 3}, max_depth=12\n",
    "            ))\n",
    "        ]\n",
    "    )\n",
    "    pipe.fit(X, y)\n",
    "    save_object(pipe, pipeline_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c41d41b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:13.423887Z",
     "start_time": "2022-06-07T21:19:13.420355Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(data_raw):\n",
    "    cleaned_data = clean_raw_data(data_raw)\n",
    "    X_train, X_val, y_train, y_val = split_train_data_raw(cleaned_data, target_feature)\n",
    "    # Train model and predict\n",
    "    train_model(X_train, y_train)\n",
    "    y_pred = predict(X_val)\n",
    "    return y_val, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ed040d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:14.231404Z",
     "start_time": "2022-06-07T21:19:13.823828Z"
    }
   },
   "outputs": [],
   "source": [
    "raw = pd.read_csv('./dataset_train_test.csv', sep=';')\n",
    "y_val, y_pred = build_model(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c4b5c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:15.878085Z",
     "start_time": "2022-06-07T21:19:15.866006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "    Data architecte       0.66      0.98      0.79       430\n",
      "      Data engineer       0.98      0.66      0.79       572\n",
      "     Data scientist       0.90      0.72      0.80       849\n",
      "Lead data scientist       0.49      0.75      0.59       282\n",
      "\n",
      "           accuracy                           0.76      2133\n",
      "          macro avg       0.76      0.78      0.74      2133\n",
      "       weighted avg       0.82      0.76      0.77      2133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "le = load_object(target_encoder_filename)\n",
    "print(classification_report(y_val, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a8f7f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:19.351127Z",
     "start_time": "2022-06-07T21:19:19.347938Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_predictions(predict_data_raw):\n",
    "    y_pred = predict(predict_data_raw)\n",
    "    le = load_object(target_encoder_filename)\n",
    "    return le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e653cef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T21:19:21.682036Z",
     "start_time": "2022-06-07T21:19:21.646374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data scientist', 'Data engineer', 'Lead data scientist',\n",
       "       'Data scientist', 'Data scientist', 'Data architecte',\n",
       "       'Data scientist', 'Data scientist', 'Lead data scientist',\n",
       "       'Data architecte', 'Lead data scientist', 'Data architecte',\n",
       "       'Data engineer', 'Data architecte', 'Data scientist',\n",
       "       'Data engineer', 'Data scientist', 'Data architecte',\n",
       "       'Data scientist', 'Lead data scientist'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_raw = pd.read_csv('./dataset_predict.csv', sep=';')\n",
    "make_predictions(predict_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f52e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
